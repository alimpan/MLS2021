{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Classtest.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMFoP4ycV/iKXcn7JuIjUFr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWY9fHoi810T","executionInfo":{"status":"ok","timestamp":1619546657332,"user_tz":-330,"elapsed":5368,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}},"outputId":"cd3cc027-5300-4fcc-e2ad-c618d40b0c7e"},"source":["!git clone https://github.com/YoongiKim/CIFAR-10-images"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'CIFAR-10-images'...\n","remote: Enumerating objects: 60027, done.\u001b[K\n","remote: Total 60027 (delta 0), reused 0 (delta 0), pack-reused 60027\u001b[K\n","Receiving objects: 100% (60027/60027), 19.94 MiB | 70.17 MiB/s, done.\n","Resolving deltas: 100% (59990/59990), done.\n","Checking out files: 100% (60001/60001), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5TShDu_9O1M","executionInfo":{"status":"ok","timestamp":1619546690055,"user_tz":-330,"elapsed":1550,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}},"outputId":"37866e2a-e1ab-4a94-94d8-41d6b7e33f2a"},"source":["\n","!nvcc --version"],"execution_count":2,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Wed_Jul_22_19:09:09_PDT_2020\n","Cuda compilation tools, release 11.0, V11.0.221\n","Build cuda_11.0_bu.TC445_37.28845127_0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mzJp1F4G_Mac","executionInfo":{"status":"ok","timestamp":1619546697342,"user_tz":-330,"elapsed":5461,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["#importing libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from torchvision import datasets,transforms\n","import torch.nn as nn\n","import torch\n","import cv2\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVY-t5mSMnFr","executionInfo":{"status":"ok","timestamp":1619546703706,"user_tz":-330,"elapsed":1343,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}},"outputId":"c4f77fd5-6dc8-4732-8ab1-a45d36891525"},"source":["#CUDA activation\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o40OgS52vh78","executionInfo":{"status":"ok","timestamp":1619546727433,"user_tz":-330,"elapsed":3959,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["#Creating the csv files\n","import os\n","p=[]\n","c=[]\n","\n","for file_name in os.listdir(\"CIFAR-10-images/test/\"):\n","  for files in os.listdir(\"CIFAR-10-images/test/\"+file_name):\n","    if files.split(\".\")[-1].lower() in {\"jpeg\", \"jpg\", \"png\"}:\n","        path='CIFAR-10-images/test/'+file_name+'/'+files\n","        clss=file_name\n","        p.append(path)\n","        c.append(clss)\n","\n","p1=[]\n","c1=[]\n","\n","for file_name in os.listdir(\"CIFAR-10-images/train/\"):\n","  for files in os.listdir(\"CIFAR-10-images/train/\"+file_name):\n","    if files.split(\".\")[-1].lower() in {\"jpeg\", \"jpg\", \"png\"}:\n","        path='CIFAR-10-images/train/'+file_name+'/'+files\n","        clss=file_name\n","        p1.append(path)\n","        c1.append(clss)\n","\n","\n","\n","test_dataset=pd.DataFrame({'path':p,'class':c})\n","train_dataset=pd.DataFrame({'path':p1,'class':c1})\n","\n","test_d = test_dataset.to_csv('test_data.csv', index=False)\n","train_d = train_dataset.to_csv('train_data.csv', index=False)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fe9-zJE251s_","executionInfo":{"status":"ok","timestamp":1619546788051,"user_tz":-330,"elapsed":4885,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["# 3: defining data transformations\n","\n","def data_transform(x):\n","  transform=transforms.Compose([transforms.RandomRotation(25),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize([0.5,0.5,0.5],\n","                                                     [0.5,0.5,0.5])])\n","  return transform(x)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"sTEm5U191vXm","executionInfo":{"status":"ok","timestamp":1619546978275,"user_tz":-330,"elapsed":1126,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["## Step4 : Writting a custom Dataloader\n","class MyDataset():\n","  def __init__(self,image_set,dict1,argument=True):\n","    csv_reader = pd.read_csv(image_set)\n","    self.imgfiles=list(csv_reader.iloc[:,0])\n","    self.classlabels= list(csv_reader.iloc[:,1])\n","    self.argument=argument\n","    self.dict1=dict1\n","  def __len__(self):\n","    return len(self.imgfiles)\n","  def __getitem__(self,idx):\n","    img=cv2.imread(self.imgfiles[idx])\n","    if self.argument:\n","      x = Image.fromarray(img)\n","      X=data_transform(x)\n","    Y=self.dict1[self.classlabels[idx]]\n","    return X,Y"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZUAaPrfg8if","executionInfo":{"status":"ok","timestamp":1619546857474,"user_tz":-330,"elapsed":1071,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["c_dict={'airplane':0,'automobile':1,'bird':2,'cat':3,'deer':4,'dog':5\n","        ,'frog':6,'horse':7,'ship':8,'truck':9}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpElHv0uhi7V","executionInfo":{"status":"ok","timestamp":1619547017369,"user_tz":-330,"elapsed":984,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["from torch.utils.data.sampler import SubsetRandomSampler"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQg9pL9qJx1H","executionInfo":{"status":"ok","timestamp":1619547141666,"user_tz":-330,"elapsed":1621,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["## Preparing the iterators:\n","def prep_iter():\n","  c_dict={'airplane':0,'automobile':1,'bird':2,'cat':3,'deer':4,'dog':5\n","        ,'frog':6,'horse':7,'ship':8,'truck':9}\n","\n","  train_data=MyDataset('train_data.csv',c_dict)\n","  test_data=MyDataset('test_data.csv',c_dict,argument=False)\n","\n","  batch_size=20\n","  num_workers=0\n","  valid_size=0.2\n","\n","  # obtain training indices that will be used for validation\n","  num_train = len(train_data) \n","  indices = list(range(num_train))\n","  np.random.shuffle(indices)\n","  split = int(np.floor(valid_size * num_train))\n","  train_idx, valid_idx = indices[split:], indices[:split]\n","\n","  # define samplers for obtaining training and validation batches\n","  train_sampler = SubsetRandomSampler(train_idx)\n","  valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","      sampler=train_sampler, num_workers=num_workers)\n","  valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n","      sampler=valid_sampler, num_workers=num_workers)\n","  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n","      num_workers=num_workers)\n","\n","  return train_loader,valid_loader,test_loader"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"kP2vXHdGiPnJ","executionInfo":{"status":"ok","timestamp":1619547220936,"user_tz":-330,"elapsed":3240,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","  def __init__(self):\n","    super(CNN,self).__init__()\n","    self.conv1=nn.Conv2d(3,16,3,padding=1)\n","    self.conv2=nn.Conv2d(16,32,3,padding=1)\n","    self.conv3=nn.Conv2d(32,64,3,padding=1)\n","    self.pool=nn.MaxPool2d(2,2)\n","    self.fc1=nn.Linear(64*4*4,500)\n","    self.fc2=nn.Linear(500,10)\n","    self.dropout=nn.Dropout(0.25)\n","  def forward(self,x):\n","    x=self.pool(F.relu(self.conv1(x)))\n","    x=self.pool(F.relu(self.conv2(x))) \n","    x=self.pool(F.relu(self.conv3(x)))\n","    x=x.view(-1,64*4*4)  #flattening\n","    x=self.dropout(x) \n","    x=F.relu(self.fc1(x))\n","    x=self.dropout(x)\n","    x=F.relu(self.fc2(x))\n","    \n","    return x"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxvKIpOniV7v","executionInfo":{"status":"ok","timestamp":1619547365301,"user_tz":-330,"elapsed":1051,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["\n","\n","def train(n_epochs,train_loader,valid_loader):\n","  # create a complete CNN\n","  model = CNN()\n","  #print(model)\n","\n","  # move tensors to GPU if CUDA is available\n","  if train_on_gpu:\n","      model.cuda()    \n","  # specify loss function (categorical cross-entropy)\n","  criterion = nn.CrossEntropyLoss()\n","\n","  # specify optimizer\n","  optimizer = optim.SGD(model.parameters(), lr=0.01)\n","  \n","  valid_loss_min = np.Inf # track change in validation loss\n","  t_loss=[]\n","  v_loss=[]\n","  for epoch in range(1, n_epochs+1):\n","\n","      # keep track of training and validation loss\n","      train_loss = 0.0\n","      valid_loss = 0.0\n","    \n","      ###################\n","      # train the model #\n","      ###################\n","      model.train()\n","      for data, target in train_loader:\n","          #target=torch.Tensor(target)\n","          # move tensors to GPU if CUDA is available\n","          if train_on_gpu:\n","              data = data.cuda()\n","              target=target.cuda()\n","          # clear the gradients of all optimized variables\n","          optimizer.zero_grad()\n","          # forward pass: compute predicted outputs by passing inputs to the model\n","          output = model(data)\n","          # calculate the batch loss\n","          loss = criterion(output, target)\n","          # backward pass: compute gradient of the loss with respect to model parameters\n","          loss.backward()\n","          # perform a single optimization step (parameter update)\n","          optimizer.step()\n","          # update training loss\n","          train_loss += loss.item()*data.size(0)\n","        \n","      ######################    \n","      # validate the model #\n","      ######################\n","      model.eval()\n","      for data, target in valid_loader:\n","          # move tensors to GPU if CUDA is available\n","          if train_on_gpu:\n","              data, target = data.cuda(), target.cuda()\n","          # forward pass: compute predicted outputs by passing inputs to the model\n","          output = model(data)\n","          top_p,top_class=output.topk(1,dim=1)\n","          equalstry=top_class==target\n","          equals=top_class==target.view(*top_class.shape)\n","          accuracy=torch.mean(equals.type(torch.FloatTensor))\n","          # calculate the batch loss\n","          loss = criterion(output, target)\n","          # update average validation loss \n","          valid_loss += loss.item()*data.size(0)\n","    \n","      # calculate average losses\n","      train_loss = train_loss/len(train_loader.sampler)\n","      valid_loss = valid_loss/len(valid_loader.sampler)\n","\n","      t_loss.append(train_loss)\n","      v_loss.append(valid_loss) \n","\n","      # print training/validation statistics \n","      print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","          epoch, train_loss, valid_loss))\n","    \n","      # save model if validation loss has decreased\n","      if valid_loss <= valid_loss_min:\n","          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","          valid_loss_min,\n","          valid_loss))\n","          torch.save(model.state_dict(), 'model_cifar.pt')\n","          valid_loss_min = valid_loss\n","          print(f'Accuracy: {accuracy.item()*100}%')"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"BrLt6Avgjv0B","executionInfo":{"status":"ok","timestamp":1619547598814,"user_tz":-330,"elapsed":1167,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}}},"source":["from torch import optim"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"6RzwGps6i5tu","executionInfo":{"status":"error","timestamp":1619547601000,"user_tz":-330,"elapsed":1379,"user":{"displayName":"alimpan barik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpdnj6d6FHgUd8lh8Vqgj2Pw4ldmE32sSJYEnKOg=s64","userId":"12238577403209403040"}},"outputId":"66f93734-5de8-4ab0-cf6b-3c1889c182df"},"source":["train(30,train_loader,valid_loader)"],"execution_count":24,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-f343e9942722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-940533b970ac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m###################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m           \u001b[0;31m#target=torch.Tensor(target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0;31m# move tensors to GPU if CUDA is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-74cad880b88f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasslabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"]}]},{"cell_type":"code","metadata":{"id":"_Xtex8KDjvAS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SeRwFeOi_yA"},"source":[""],"execution_count":null,"outputs":[]}]}