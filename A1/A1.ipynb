{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "removed-decade",
   "metadata": {},
   "source": [
    "# Under Gaussian noise assumption linear regression amounts to least square:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-alaska",
   "metadata": {},
   "source": [
    "##### Alimpan Barik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-assessment",
   "metadata": {},
   "source": [
    "##### February 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-dublin",
   "metadata": {},
   "source": [
    "## 1.Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-olympus",
   "metadata": {},
   "source": [
    "linear regression attempts to model the relationship between two variables by fitting a line to the observed data.One variable is considered to be the independent variable and the other is considered to be the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-contractor",
   "metadata": {},
   "source": [
    "## 2. Probabilistic model of Linear Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-barbados",
   "metadata": {},
   "source": [
    "### 2.1. Linear model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-discipline",
   "metadata": {},
   "source": [
    "Suppose we are given a dataset D={${x_i},{y_i}$}. $\\\\$\n",
    "${x_i}$ is known as the feature and ${y_i}$'s are known as the target/label. We want to fit a line to the given data. Suppose we want to fit a line-\n",
    "$${y_i}\\simeq\\theta^T{x_i}$$\n",
    "$$\\Rightarrow {y_i}=\\theta^T{x_i}+\\epsilon_i$$\n",
    "where $\\epsilon_i$'s are random noise to model unknown effects.\n",
    "$\\epsilon_i$'s are i.i.ds and by our assumption they follow normal distrubution . \n",
    "i.e. $${\\epsilon_i} \\sim N(0,\\sigma^2)$$\n",
    "$$\\Rightarrow p(\\epsilon_i)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp \\left (^\\frac{-\\epsilon_i^2}{2\\sigma^2} \\right ) $$\n",
    "$$\\Rightarrow p(y_i-\\theta^Tx_i)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp\\left(^\\frac{-(y_i-\\theta^Tx_i)^2}{2\\sigma^2}\\right)$$ \\\n",
    "However  the conventional way to write the probability is\n",
    "$$  p(y_i|x_i;\\theta)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp\\left(^\\frac{-(y_i-\\theta^Tx_i)^2}{2\\sigma^2}\\right)$$ \\\n",
    "Now from Bayes' Theorem: \n",
    "$$ P(\\theta|D)=P(D|\\theta)\\frac{P(\\theta)}{P(D)} $$\n",
    "$$\\Rightarrow P(\\theta|D)=\\frac{P(\\theta,D)}{P(D)}=\\frac{P(D|\\theta)P(\\theta)}{\\sum\\nolimits_{\\theta} \n",
    "P(D|\\theta)P(\\theta)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-toronto",
   "metadata": {},
   "source": [
    "### 2.2. Maximum Likelihood Estimation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-edgar",
   "metadata": {},
   "source": [
    "$$\\theta^*   = \\underset{}{{argmax}}_{\\theta}  L (\\theta |{D}) $$\n",
    "$$= \\underset{}{{argmax}}_\\theta P({D}|\\ \\theta))$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta P(y_{1},x_{1},...,y_{m},x_{m};\\theta)$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta \\prod_{i = 1}^{m} P(y_{i},x_{i} ; \\theta)$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta \\prod_{i = 1}^{m} [P(y_{i}|x_{i} ; \\theta). P(x_{i}; \\theta ]$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta \\prod_{i = 1}^{m} [P(y_{i}| x_{i} ; \\theta)] . P(x_{i})$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta \\prod_{i = 1}^{m} [P(y_{i}| x_{i} ; \\theta)]$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta\\quad\\sum_{i = 1}^{m}  log P(y_{i} | x_{i} ; \\theta )$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta\\quad\\sum_{i=1}^{m} \\left[log\\left(\\frac{1}{\\sqrt{2 \\pi}\\sigma}\\right) + log\\left(exp(^-\\frac{(\\theta^T x_{i} - y_{i})^2}{2 \\sigma^2})\\right)\\right]$$\n",
    "$$= \\underset{}{\\operatorname{argmax}}_\\theta  - \\frac{1}{2 \\sigma^2} \\quad\\sum_{i=1}^{m} (\\theta^T x_{i} - y_{i})^2$$\n",
    "$$= \\underset{}{\\operatorname{argmin}}_\\theta  \\frac{1}{m}\\quad\\sum_{i=1}^{m} (\\theta^T x_{i} - y_{i})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-tomorrow",
   "metadata": {},
   "source": [
    "### 2.3. Conclusion:\n",
    "Hence under the Gaussian noise assumption (i.e.  when the error/noise terms follow Normal distribution) , the linear regression amounts to least square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-flight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
